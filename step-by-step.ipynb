{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78189bba-7334-4c67-b6f6-650828929e03",
   "metadata": {},
   "source": [
    "# Make things disappear with XMem and FGT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73de4537-fd27-4947-807e-e71e35522541",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- [ECCV 2022] XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model: https://github.com/hkchengrex/XMem\n",
    "- [ECCV 2022] Flow-Guided Transformer for Video Inpainting: https://github.com/hitachinsk/fgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e96e030-b23f-4c85-ac98-71b664a887ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists as path_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8778441f-8efd-49f4-9a0c-3287de21b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "except ImportError:\n",
    "    !pip install torch==1.10.1\n",
    "    !pip install torchvision==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d28076-f695-4642-a478-bc37078f0ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: nvidia-smi: not found\n",
      "CUDA not available. Please connect to a GPU instance if possible.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU')\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('CUDA not available. Please connect to a GPU instance if possible.')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9c8cb-8bff-4ce6-ba52-4cfae4745984",
   "metadata": {},
   "source": [
    "## (a) Load video from YouTube and split into frames\n",
    "- Source: https://huggingface.co/spaces/YiYiXu/it-happened-one-frame-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c04560a-cf27-44c2-9026-30b4dc99a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists('helper.py'):\n",
    "    !wget https://huggingface.co/spaces/YiYiXu/it-happened-one-frame-2/raw/main/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d426356-cf2a-4da1-b93c-1a6a7fec6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import youtube_dl\n",
    "except:\n",
    "    !pip install youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6131293-3ead-455b-a0e1-74ff2fbc196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 181MiB/s]\n",
      "/home/studio-lab-user/.conda/envs/machinelearnear-default/lib/python3.9/site-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/machinelearnear-default/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/home/studio-lab-user/.conda/envs/machinelearnear-default/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/home/studio-lab-user/.conda/envs/machinelearnear-default/lib/python3.9/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n",
      "/home/studio-lab-user/.conda/envs/machinelearnear-default/lib/python3.9/site-packages/gradio/outputs.py:42: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from helper import vid2frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d708433-b71b-421a-a887-ed4e4dda197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = 'https://youtu.be/KOnfiFOCwH0' # Trump leaves Argentinean president alone on stage at G20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a29696f-3184-468e-9fe3-d72f9e980687",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_frames, path_frames = vid2frames(youtube_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d40495-a306-4143-a8c4-1b765ca01e38",
   "metadata": {},
   "source": [
    "## Predict Video Segmentation Mask\n",
    "### `Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model`\n",
    "- Source: https://colab.research.google.com/drive/1RXK5QsUo2-CnOiy5AOSjoZggPVHOPh1m?usp=sharing#scrollTo=MWGdN7XCSYSm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59856b-e363-4219-9df6-6085653c14fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get our code and install pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b726f5ce-8db1-4acb-83f3-f376d4b5e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists('XMem'):\n",
    "    !git clone https://github.com/hkchengrex/XMem.git\n",
    "    !pip install -r XMem/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944268d0-d078-4991-b875-dce487679fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cv2\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    !pip install opencv-python\n",
    "    !pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64dca9-d66c-4610-938d-c7330ab5e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import detectron2\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Please install detectron2. Check \"\n",
    "        \"`https://detectron2.readthedocs.io/en/latest/tutorials/install.html` \"\n",
    "        \"for installation details.\"\n",
    "    )\n",
    "    !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0abd7-d62b-4d31-977b-e15335aa9512",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Download the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bcc4a3f-8bbf-4ea8-88da-3681137bf4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists('XMem/saves/XMem.pth'):\n",
    "    !wget -P ./XMem/saves/ https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441ea10-0a7e-40a1-8f18-f3dfaee15ed6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986cc69-1206-4973-b5e5-74edfbb73eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from inference.data.test_datasets import LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n",
    "from inference.data.mask_mapper import MaskMapper\n",
    "from model.network import XMem\n",
    "from inference.inference_core import InferenceCore\n",
    "\n",
    "from progressbar import progressbar\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# default configuration\n",
    "config = {\n",
    "    'top_k': 30,\n",
    "    'mem_every': 5,\n",
    "    'deep_update_every': -1,\n",
    "    'enable_long_term': True,\n",
    "    'enable_long_term_count_usage': True,\n",
    "    'num_prototypes': 128,\n",
    "    'min_mid_term_frames': 5,\n",
    "    'max_mid_term_frames': 10,\n",
    "    'max_long_term_elements': 10000,\n",
    "}\n",
    "\n",
    "network = XMem(config, './saves/XMem.pth').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f53fd88-f9e7-4878-a2d7-2bd778ce4296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f79ab5-8592-4d92-b3eb-a4c5d80459f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb993e19-88ca-40c9-bb50-7af9060c55b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'clip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vid2frames\n",
      "File \u001b[0;32m~/make-things-disappear-with-XMem-and-FGT/src/app.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclip\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01myoutube_dl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image,ImageDraw, ImageFont\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'clip'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62bf7a5-f95b-478c-a261-7fd30dfa601f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd2bcc8d-02e3-4234-9574-e1abca73dddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71ff742-63c9-4ea3-b897-76ff1ce22cc1",
   "metadata": {},
   "source": [
    "### Preview the video and first-frame annotation\n",
    "The first frame mask is a PNG with a color palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54585f3-fff3-468d-80ba-841254105842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(open(video_name, 'rb').read()).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079f5e7-b7b5-4218-a4d3-581c2859f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "IPython.display.Image('first_frame.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a4241-3558-448d-822c-571c1b53e18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4550d-af9f-4718-8047-4a5310133599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c3cdf-b239-42f8-8bad-ca661ec467d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearnear-default:Python",
   "language": "python",
   "name": "conda-env-machinelearnear-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
